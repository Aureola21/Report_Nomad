\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{float}
\usepackage{titlesec}
\usepackage[margin=1in]{geometry}
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\title{Training and Perception for Nomad Navigation}
\author{Authors \ Mathematics and Computing \\ Indian Institute of Science}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This report presents our work on implementing and analyzing the training and perception components of a visual navigation system based on diffusion policies, as adapted from the NOMAD (Navigation with Goal Masked Diffusion) framework. 
Our approach combines a visual perception backbone with a trajectory diffusion model to support both goal-directed and exploratory navigation. We trained our model on the SACSoN dataset, which features diverse real-world trajectories across various environments and robot platforms. 
We leverage a conditional diffusion model to generate multimodal waypoint predictions, enabling the agent to reason about complex, uncertain navigation scenarios. Our contributions include a detailed breakdown of the model architecture, training methodology, and evaluation metrics—particularly focusing on waypoint alignment through cosine similarity. 
We have left out the deployment aspects.
\end{abstract}

\section{Introduction}
Robotic learning for navigation in unfamiliar environments requires the ability to perform both task-oriented navigation (i.e., reaching a known goal) and task-agnostic exploration (i.e., searching for a goal in a novel environment). Traditionally, these functionalities are tackled by separate systems — for example, using subgoal proposals, explicit planning modules, or distinct navigation strategies for exploration and goal-reaching.

\subsection*{What is NoMaD?}
NoMaD is a transformer-based diffusion policy designed for long-horizon, memory-based navigation, that can:
\begin{itemize}
    \item Explore unknown places on its own (goal-agnostic behavior).
    \item Go to a specific place or object when given a goal image (goal-directed behavior).
\end{itemize}
Our project involves implementing the NoMaD Policy adapting its Transformer-based architecture and conditional diffusion decoder
to learn from a rich, multimodal dataset (SACSoN) composed of real-world trajectories.
Unlike traditional latent-variable models or methods that rely on separate generative components for subgoal planning, the unified diffusion policy exhibits superior generalization and robustness in unseen environments, while maintaining a compact model size.
In this report, we focus on the perception and training components of this policy, emphasizing how a strong visual encoder combined with a diffusion-based decoder leads to improved alignment of predicted and ground-truth waypoints. We analyze the training dynamics, present key quantitative metrics such as cosine similarity and distance loss, and highlight the model’s ability to generalize across diverse scenarios.

\subsection*{Overview of NoMaD Architecture}
Refer to the Appendix A for preliminaries.

\section{Implementation Details}
\subsection{Environment Setup}
% The codebase was adapted from an open-source repository. 
% Major libraries used include PyTorch, Hydra for configuration, and torchvision. 
% The PYTHONPATH had to be correctly exported due to a nested diffusion_policy folder structure.

\subsection{Data Pipeline}
We used a pre-collected dataset of trajectories containing RGB observations, actions, and ground-truth waypoints. Data augmentations were not used in our initial experiments.

\subsection{Training Procedure}
Training was done on a single NVIDIA GPU using a batch size of 64. The training loop involved:
\begin{itemize}
\item Calculating diffusion loss from predicted vs ground-truth waypoints.
\item Waypoint cosine similarity.
\item Auxiliary action prediction losses.
\end{itemize}
Training checkpoints were saved every epoch. EMA models were also stored.

\section{Perception Module}
The ResNet18 backbone encodes RGB frames, while a transformer-based encoder maintains temporal context. This allows the policy to act based on history, crucial for long-horizon navigation.

\subsection{Cosine Similarity Metrics}
We track waypoint cosine similarity to evaluate how well the predicted and ground-truth waypoints align. Early training epochs show increasing cosine similarity, indicating improved waypoint alignment.

\section{Results}
\subsection{Training Metrics}
\begin{itemize}
\item Final training loss: \textasciitilde1.11
\item Cosine similarity: \textasciitilde0.47 (multi-action waypoints)
\item Distance loss: \textasciitilde128
\end{itemize}

\subsection{Observations}
Loss plateaued after around 5,000 batches. Training logs show improvement in cosine similarity and reduction in loss. Action losses remained stable across UC and GC branches.

\section{Challenges and Debugging}


\section{Conclusion and Future Work}
We successfully trained the NOMAD policy and analyzed the perception module. Future work could involve domain randomization, hyperparameter tuning, and evaluating transfer to real-world or simulated environments.

\section*{References}
\begin{enumerate}
\item H. Janner et al., "NOMAD: Planning with Diffusion for Visual Navigation," 2022.
\item Diffusion Policy GitHub Repository: \url{https://github.com/wayveai/diffusion-policy}
\end{enumerate}
\end{document}